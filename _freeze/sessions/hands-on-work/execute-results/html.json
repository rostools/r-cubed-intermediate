{
  "hash": "429d8ee7403d6e66f41e5088282872fa",
  "result": {
    "markdown": "# Hands-on exercises {#hands-on-work}\n\n::: callout-warning\nWe're still testing to see what best works for this section.\n:::\n\nThis session is all about reinforcing the skills you've learned in this\ncourse by continuing to use them. You can either continue working on the\nMMASH dataset and complete the exercises below or you could try to apply\nthese skills to another dataset (such as your own). If you continue with\nthe MMASH, we strongly encourage you to work together with your group to\nask questions and to help each other out in understanding what to do and\nwhat to code (we are also here for help).\n\n## Quick recap of workflow {#sec-general-workflow}\n\n::: {.callout-note appearance=\"minimal\" collapse=\"true\"}\n## Instructor note\n\nYou can go over this point verbally, reiterating what they've learned so\nfar.\n:::\n\nYou now have some skills and tools to allow you to reproducibly import,\nprocess, clean, join, and eventually analyze your datasets. Listed below\nare the general workflows we've covered and that you can use as a\nguideline to complete the following (optional) exercises and group work.\n\n-   Import with the `vroom()`, and optionally use `spec()` to `vroom()`\n    again to select specific variables.\n-   Convert importing into a function in a Quarto / R Markdown document,\n    move to the `R/function.R` script, restarting R, and `source()`.\n-   Test that joining datasets into a final form works properly while in\n    a Quarto / R Markdown document, then cut and paste the code into a\n    data processing R script in the `data-raw/` folder (alternatively,\n    you can directly write and test code while in the `data-raw/` R\n    script).\n-   Restart R and generate the `.rda` dataset in the `data/` folder by\n    sourcing the `data-raw/` R script.\n-   Restart R, load the new dataset with `load()` and put the loading\n    code into a Quarto / R Markdown document.\n-   Add any additional cleaning code to the data processing R script in\n    `data-raw/` and update the `.rda` dataset in `data/` whenever you\n    encounter problems in the dataset.\n-   Write R in code chunks in a Quarto / R Markdown document to further\n    analyze your data and check reproducibility by often rendering to\n    HTML.\n    -   Part of this workflow is to also write R code to output in a way\n        that looks nice in the HTML (or Word) formats by mostly creating\n        tables or figures of the R output.\n-   Use Git often by adding and committing into the history so you never\n    lose stuff and can keep track of changes to your files.\n\n## Import and process the activity data\n\nWe have a few other datasets that we could join together, but would\nlikely require more processing in order to appropriately join with the\nother datasets. Complete these tasks in the `doc/learning.qmd` file:\n\n1.  Create a new header called `## Exercise: Importing activity data`\n2.  Create a new code chunk below this new header\n    {{< var keybind.chunk >}}.\n3.  Starting the workflow from the beginning (e.g. with the `spec()`\n    process), write code that imports the `Activity.csv` data into R.\n4.  Convert this code into a new function using the workflow you've used\n    from this course:\n    -   Call the new function `import_activity`.\n    -   Include one argument called `file_path`.\n    -   Test that it works.\n    -   Add Roxygen documentation with {{< var keybind.roxygen >}} and\n        explicit package links (`::`) with the functions.\n    -   Move the newly created function into the `R/functions.R`.\n    -   Use the new function in `doc/learning.qmd` and use `source()`\n        {{< var keybind.source >}} to run it.\n5.  Import all the `user_` datasets with `import_multiple_files()` and\n    the `import_activity()` function.\n6.  Pipe the results into `mutate()` and create a new column called\n    `activity_seconds` that is based on subtracting `end` and `start`.\n    -   Use `?mutate` and check the examples in the help document that\n        pops up if you don't recall how to use this function.\n7.  You'll notice that the `activity` column is numeric. Look into the\n    [Data Description](https://physionet.org/content/mmash/1.0.0/) and\n    find out what each column represents and what the numbers mean in\n    the column `activity`. Then think about or complete these tasks:\n    -   What is the advantage and disadvantage of using numbers instead\n        of text to describe categorical data like in the `activity`\n        column?\n    -   Using the `case_when()` function (within `mutate()`) we learned\n        about, convert the `activity` numbers into more meaningful\n        character data.\n8.  Render the Quarto document with {{< var keybind.render >}} to see if\n    it is reproducible.\n9.  Run styler with {{< var keybind.styler >}}.\n10. **Add and commit** your changes to the Git history with\n    {{< var keybind.git >}}.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"**Click for the solution**. Only click if you are struggling or are out of time.\"}\nimport_activity <- function(file_path) {\n  activity_data <- vroom::vroom(\n    file_path,\n    col_select = -1,\n    col_types = vroom::cols(\n      activity = vroom::col_double(),\n      start = vroom::col_time(format = \"\"),\n      end = vroom::col_time(format = \"\"),\n      day = vroom::col_double(),\n      .delim = \",\"\n    ),\n    .name_repair = snakecase::to_snake_case\n  )\n  return(activity_data)\n}\n\nactivity_df <- import_multiple_files(\"Activity.csv\", import_activity)\n\nactivity_df %>%\n  mutate(activity_duration = end - start)\n```\n:::\n\n\n## Fix up some remaining data issues\n\nThere are some issues with the data still. Try to work through these\ntasks to clean the data up more.\n\n1.  Use the code below to examine the cleaned data for user 21. Notice\n    some problems? Go into the raw data as well as the data\n    documentation on the [MMASH\n    website](https://physionet.org/content/mmash/1.0.0/) and try to\n    figure how what happened. How you might fix the problem? Try your\n    fix within the `data-raw/mmash.R` cleaning script.\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    mmash %>% \n      filter(user_id == \"user_21\")\n    ```\n    :::\n\n\n    -   **Hint**: Look into user 21's folder at their `.csv` files they\n        have. Compare to the other users. Are the same number of files\n        there?\n    -   **Hint**: In the `reduce()` and `full_join()` code, try\n        re-arranging the order that the datasets are listed. Does order\n        matter?\n\n2.  If you do `count(mmash, day)` in the Console while the `mmash`\n    dataset is loaded, you'll see that the `day` column has a weird\n    value of `-29`. Use `filter()` to see which rows and users are\n    affected. Look into the data documentation on the [MMASH\n    website](https://physionet.org/content/mmash/1.0.0/) and see if you\n    can find an explanation for this. How would you go about solving\n    this issue? Write up code to fix this issue in the\n    `data-raw/mmash.R` script.\n\n    -   **Hint**: Find the users that have this value and look into\n        their data `.csv` files that have `day` (or `Day`) variables.\n        Which files have this `-29` in the `day` column? Where does the\n        `-29` value start in that data file? Can you guess what the\n        issue was and what `-29` is or should be?\n\n## Process and join sleep and questionnaire data\n\nThere are still a few datasets that you can join in with the current\ndatasets like `sleep.csv` and `questionnaire.csv`. Using the workflows\nin @sec-general-workflow as a guide, start from the beginning and\nimport, process, clean, make functions, and join these two datasets in\nwith the others so that they get included in the `data/mmash.rda` final\ndataset. Afterwards, do some descriptive analysis using the function\n`tidy_summarise_by_day()`.\n\n::: {.callout-tip appearance=\"default\"}\nUser 11 has no sleep data, so you will eventually have to drop user 11\nfrom the dataset before summarizing the data.\n:::\n\n## Create a second dataset of only the Actigraph and RR data\n\nThe Actigraph and RR datasets contain a lot of interesting and useful\ndata that gets destroyed when we first summarise and then join them with\nthe other datasets. While we can't meaningfully join all this data with\nthe other datasets, we can join them on their own as separate datasets.\n\nUsing the workflows in @sec-general-workflow as a guide, start from the\nbeginning and import, process, clean, make functions, and create a final\ndataset of only the `Actigraph.csv` and `RR.csv` datasets.\n\n-   Join only these two datasets by `user_id`, `day`, and `time`.\n-   Name the new dataset `actigraph_rr` and save it to `data/` by using\n    another `usethis::use_data()` line in the `data-raw/mmash.R` script.\n\nThan think of how some of these questions might be answered, using the\n[Data Description](https://physionet.org/content/mmash/1.0.0/) as a\nguide:\n\n1.  What times of the day are people lying down (`inclinometer_lying`)\n    most often? How long are they lying down for?\n2.  When are people most likely to be sitting down\n    (`inclinometer_sitting`)? Does this also correspond to a lower heart\n    rate or a lower interbeat interval (from the `RR` data) compared to\n    when standing?\n3.  Are people who have more activity throughout the day also reporting\n    better sleep quality (like `number_of_awakenings`)?\n4.  Does the self-reported activity match the accelerometry data?\n\n## Other datasets to try out\n\nIf you have completed the exercises above and still wanted to practice\nthe skills, here are some other datasets you can use (aside from your\nown):\n\n-   [MIMIC-IV demo data in the OMOP Common Data\n    Model](https://physionet.org/content/mimic-iv-demo-omop/0.9/)\n-   [RR interval time series from healthy\n    subjects](https://physionet.org/content/rr-interval-healthy-subjects/1.0.0/)\n-   [Data on the 2021 Olympics in\n    Tokyo](https://www.kaggle.com/arjunprasadsarkhel/2021-olympics-in-tokyo)\n-   Find your own dataset from\n    [PhysioNet](https://physionet.org/about/database/#open) or\n    [Zenodo](https://zenodo.org/search?page=1&size=20&q=diabetes&access_right=open&file_type=xlsx&file_type=csv&file_type=zip&type=dataset#).\n-   Work on the game [\"Murder\n    Mystery\"](https://andersaskeland.github.io/R-murder-mystery) (which\n    Anders Askeland converted into a game using R).\n",
    "supporting": [
      "hands-on-work_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}