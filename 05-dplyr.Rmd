# Workflow to analyzing your tidy data {#dplyr-2}

![](https://img.shields.io/badge/document%20status-in%20progress-red?style=flat-square)

```{r, eval=TRUE, child="includes/preamble.Rmd"}
```

`r '<!-- '`

```{r setup-05, include=FALSE, eval=FALSE}
source("R/functions.R")
library(here)
library(fs)
library(tidyverse)
library(vroom)
source_session("03-dry.Rmd")
source_session("04-dplyr.Rmd")
load("data/mmash.rda")
```

```{r}
knitr::opts_chunk$set(eval = FALSE)
```

Here we will continue using the *Workflow* block as we cover the fourth block,
"*Work with final data*" in Figure \@ref(fig:diagram-overview-4).

```{r diagram-overview-4, fig.cap="Section of the overall workflow we will be covering.", echo=FALSE}
diagram_overview(4)
```

And your folder and file structure should look like:

```
LearnR3
├── data/
│   ├── mmash.rda
│   └── README.md
├── data-raw/
│   ├── mmash-data.zip
│   ├── mmash/
│   │  ├── user_1
│   │  ├── ...
│   │  └── user_22
│   └── mmash.R
├── doc/
│   ├── README.md
│   └── lesson.Rmd
├── R/
│   ├── functions.R
│   └── README.md
├── .Rbuildignore
├── .gitignore
├── DESCRIPTION
├── LearnR3.Rproj
└── README.md
```

## Setup for the analysis in R Markdown

We now have a working dataset to start doing some simple analyses on in the
R Markdown document. A recommended workflow with R Markdown is to often
"Knit" it and make sure your analysis is reproducible (while on your computer).
So let's first clean it up and start from the beginning again.

Before we do that, make sure to add and commit all changes done in `doc/lesson.Rmd`.
So any change that we make now we will still have the old stuff in the history
that we can look at.

Next, we'll delete everything right below the `setup` code chunk.
This code chunk should have all the packages listed with `library()` functions.
We'll also add another one right below them:

```r
devtools::load_all()
```

When everything has been deleted, add and commit these changes into the Git history.
Then, we'll "Knit" our R Markdown document into HTML by using the "Knit" button
at the top of the pane or with `Ctrl-Shift-K`. Once it creates the file, it should
either pop up or open in the Viewer pane on the side. 

As we write more R code and do some simple analyses of the data, we are going
to be knitting often. The main reason for this is to ensure that whatever we
are writing and done will at least be reproducible on our computer, since
R Markdown is designed to ensure the document is reproducible.

For this specific workflow and for checking reproducibility, you should output
to HTML rather than to a Word document. While you can create a Word document by
changing the `output: html_document` to `output: word_document` at the top in
the YAML header, you'd only do this when you need to submit to a journal or
need to email to co-authors for review. The reason is simple: After you generate
the Word document from R Markdown, the Word file opens up and consequently Word
locks the file from further edits. What that means is that every time you generate
the Word document, you have to close it before you can generate it again,
otherwise knitting will fail. This can get annoying very quickly (trust me),
since you don't always remember to close the Word document. If you output to
HTML, this won't be a problem.

## Split-apply-combine technique

In the beginner course, we covered the 
[split-apply-combine](https://r-cubed-v2.rostools.org/wrangling.html#split-apply-combine-summarizing-data)
approach to doing data analysis. The method is: split the data into groups,
apply some analysis to each group, and then combine the results back together.
You've already used this approach when summarizing the RR and Actigraph datasets
in last session. We're going to continue using it because of its usefulness
and power. 

Let's do some descriptive statistics. Let's find out the mean and standard 
deviations of some variables by day. We will use `group_by()` and `summarise(across())`
like previously. First, in `doc/lesson.Rmd` create a new header called `##
Split-apply-combine` and make a new code chunk below it.

```{r}
mmash %>% 
    group_by(day) %>% 
    summarise(across(
        c(age, weight),
        list(mean = mean, sd = sd), 
        na.rm = TRUE
    ))
```

We can see from this that there is a random day of `-29` with `NaN` for age and
weight, as well as a missing day where mean age is 28 and mean weight is 70.
We can always fix this at a later point, but for now, we will ignore them.
Let's look at some other summary statistics, like `min()` and `max()`.
We add these into the `list()` with the other statistics:

```{r}
mmash %>% 
    group_by(day) %>% 
    summarise(across(
        c(age, weight),
        list(mean = mean, sd = sd, 
             min = min, max = max), 
        na.rm = TRUE
    ))
```

We could keep adding other variables and other summary statistics, but 
you can see the dataset is quickly become harder and harder to read.
One way we can fix this is by convert data to the long format,
since a longer format is easier for the eye to scan than a wider format.

## Pivot data to long format

`r details_for_instructors("
Walk through and explain this section, making use of the tables and graphs.
")`

Pivoting is an extremely useful action when working with data. Pivoting is when
you convert data between longer forms (more rows) and wider forms (more columns).
The [tidyr] package within tidyverse contains two wonderful functions for pivoting:
`pivot_longer()` and `pivot_wider()`. There is a well written documentation
on pivoting in the [tidy website][tidyr-pivoting] that can explain more about it.
The first thing we'll use, and probably the more commonly used in general,
is `pivot_longer()`. This function is commonly used because entering data in
the wide form is easier and more time efficient than entering data in long form.
For instance, if you were measuring glucose values over time in participants,
you might enter data in like this:

[tidyr]: https://tidyr.tidyverse.org/index.html
[tidyr-pivoting]: https://tidyr.tidyverse.org/articles/pivot.html

```{r table-example-wide, echo=FALSE}
example_wide <- tribble(
    ~person_id, ~glucose_0, ~glucose_30, ~glucose_60,
    1, 5.6, 7.8, 4.5,
    2, 4.7, 9.5, 5.3,
    3, 5.1, 10.2, 4.2
) 

example_wide %>% 
    knitr::kable(caption = "Example of a **wide** dataset that is useful for data entry.",
                 align = "c")
```

However, when it comes time to analyze the data, this wide form is very inefficient
and difficult to computationally and statistically work with. So, we do data
entry in wide and use functions like `pivot_longer()` to get the data ready for
analysis. Figure \@ref(fig:image-pivot-longer) visually shows what happens when
you pivot from wide to long.

```{r image-pivot-longer, fig.cap="Pivot longer in tidyr. New columns are called 'name' and 'value'.", out.width="70%", echo=FALSE}
knitr::include_graphics(here::here("images/pivot-longer.svg"))
```

If you had, for instance, an ID column for each participant, the pivoting would 
look like what is shown in Figure \@ref(fig:image-pivot-longer-id).

```{r image-pivot-longer-id, fig.cap="Pivot longer in tidyr, excluding an 'id' column. New columns are called 'name' and 'value', as well as the old 'id' column.", out.width="70%", echo=FALSE}
knitr::include_graphics(here::here("images/pivot-longer-id.svg"))
```

Pivoting is a conceptually challenging thing to grasp, so don't be disheartened
if you can't understand how it works yet. As you practice using it, you will
understand it. With `pivot_longer()`, the first argument is the data.
The other arguments are:

1. `cols`: The columns to use to convert to long form. The input is a vector
made using `c()` that contains the column names, like you would use in
`select()` (e.g. you can use the `select_helpers` like `starts_with()`, or `-`
minus to exclude).
1. `names_to`: Optional, default is `name`. If provided, it will be the name of
the newly created column (as a quoted character) that contains the original
column names.
1. `values_to`: Optional, default is `value`. Like `names_to`, sets the name of 
the new columns.

Let's try this out with `mmash`. In your `doc/lesson.Rmd` file, create a new
header called `## Pivot longer` and create a new code chunk below that. Now we can
start typing in our code:

```{r pivot-everything-error, error=TRUE}
mmash %>% 
    # pivot every column
    pivot_longer(everything())
```

Ok, this gives an error because we are mixing data types. Let's pivot only 
numbers.

```{r pivot-numeric}
mmash %>% 
    pivot_longer(where(is.numeric))
```

Nice! But not super useful. We can exclude specific columns from pivoting
with `-` before the column name, for instance with `user_id` and `day`. Let's
drop the `samples` column before pivoting:

```{r}
mmash %>% 
    select(-samples) %>% 
    pivot_longer(c(-user_id, -day, -gender))
```

## Exercise: Pivot your summarised results to longer form

Time: 10 min

Use `pivot_longer()` after the `group_by()` and `summarise()` we did previously:

```{r, eval=FALSE}
mmash %>% 
    group_by(day) %>% 
    summarise(across(
        c(age, weight),
        list(mean = mean, sd = sd), 
        na.rm = TRUE
    ))
```

1. Look into the help documentation of `ends_with()` and use it for pivoting only
the columns that end with `_mean` and `_sd`.
    - Hint: `ends_with()` is *vectorized* meaning you can give it a vector of
    column endings.
1. After using the `pivot_longer()`, knit the R Markdown document into HTML 
(`Ctrl-Shift-K` or the "Knit" button).
1. Open up the Git interface and add and commit the changes to `doc/lesson.Rmd`.

```{r solution-pivot-summary, eval=FALSE}
mmash %>% 
    group_by(day) %>% 
    summarise(across(
        c(age, weight),
        list(mean = mean, sd = sd), 
        na.rm = TRUE
    )) %>% 
    pivot_longer(ends_with(c("_mean", "_sd")))
```

## 

```{r}
mmash %>% 
    group_by(day) %>% 
    summarise(across(
        c(age, weight),
        list(mean = mean, sd = sd), 
        na.rm = TRUE
    )) %>% 
    pivot_longer(c(contains(c("_mean", "_sd"))))
```

## Pivot data to wider form

- This is nice, but we now have multiple distinct items in same column
(mean and sd), in both values and names
    - deeper into tidyselect helpers
- separate (tidyr)
- pivot_wider

You can also convert from long to wide, though this is less commonly done,
as most analyses either work better or require the long form. 
It can also be much more tricky to convert over to.
But sometimes you may need to have a wide form for your data.
Here you can use `pivot_wider()` function. Others have used `pivot_wider()` for creating summary tables for presentation or to capture data in a format needed by other tools. Like its opposite,
the first position argument is the data and the other necessary arguments are:

1. `id_cols`: This is optional as it will default to all column names. 
This argument tells `pivot_wider()` to use the given columns as the identifiers
for when converting. 
This is where the tricky part comes in, 
because 
1. `names_from`: Similar to the `pivot_longer()`, 
this is the name of the column that will make up the new columns.
Unlike in `pivot_longer()`, 
the column name given is *unquoted* since the column 
*must already exist* in the dataset.
1. `values_from`: As with above, this is the column name 
(that exists and must be given *unquoted*) 
for the values that will be in the new columns.

If we wanted to make it even wider, 
we could include `year` and `type` in the pivoting by wrapping them with `c()`
in the `names_from` argument:

```{r}
table2 %>% 
    pivot_wider(names_from = c(year, type), values_from = count)
```

The key to using `pivot_wider()` is that there are uniquely identifying rows
that allow pivoting that maintains the integrity of the data.
Since the NHANES dataset we use is for teaching purposes,
there are some cases where the same person is recorded multiple times in one survey year,
which doesn't make sense and prevents us from adequately pivoting wider.


```{r}
mmash %>% 
    group_by(day) %>% 
    summarise(across(
        c(age, weight),
        list(mean = mean, sd = sd), 
        na.rm = TRUE
    )) %>% 
    pivot_longer(c(contains(c("_mean", "_sd")))) %>% 
    separate(name, into = c("variable", "summary_statistic"), sep = "_") %>% 
    pivot_wider(names_from = summary_statistic, values_from = value) 
```

## Exercise: Convert this code into a function

Time: 15 min

Using the same workflow we've been doing throughout this course,
convert this code into a function.

1. Name the function `tidy_summarize_by_day`.
1. Create two arguments, called `data` and `columns`.
    - To work well with the pipe, put the `data` argument first.
1. Test it to see it work by using `age` in the `columns` argument.
    - It won't work and will throw an error. In the next section we will cover
    how to debug the function.
1. Move it over into `R/functions.R`, add Roxygen documentation, and use
explicit function calls with `packagename::`.
    - Don't forget, use `?functionname` to find out which package the function
    comes from.

```{r solution-summarise-function, echo=FALSE}
tidy_summarize_by_day <- function(data, columns) {
    data %>%
        dplyr::group_by(day) %>%
        dplyr::summarise(dplyr::across(columns,
                                       list(mean = mean, sd = sd),
                                       na.rm = TRUE)) %>% 
        tidyr::pivot_longer(c(dplyr::contains(c("_mean", "_sd")))) %>%
        tidyr::separate(name,
                        into = c("variable", "summary_statistic"),
                        sep = "_") %>% 
        tidyr::pivot_wider(names_from = summary_statistic, values_from = value) 
}
```

## Debugging functions in R and RStudio

- debugging in functions
    - browser()
    - And using the breakpoints when in the R script.
    - Inside talk through ways to look over code and figure things
    out in there.

- creating functions
    - and when using tidyverse functions 
    - NSE

- Discussion: How to make it so we can also add any type of summary
statistic?
    - think for a minute about this: How to get so we can also give our
    own custom summary statistics, like use min instead.

- debugging in functions
    - browser in RStudio?
    - Inside talk through ways to look over code and figure things
    out in there.
        - e.g. list(mean = mean) is named... so we could use that in
        ends_with
            - use names(list(mean = mean)) to show it.
            - use 

- Exercise: Convert function to let you add other summary functions
    - This might be challenging, ask neighbour for ideas

- Use function to output knitr table
    - knit and check out how it looks
        - don't add and commit the html or word output, at least not yet.
    - It's recommended to knit to Word only when absolutely necessary
    (e.g. emailing to co-authors for comments),
    since Word locks the file when its open, so knitting requires a 
    "close Word first" process, which gets annoying quickly.

- pipe results into mutate to make table even prettier
    - e.g. with glue::glue(mean (sd))
    
- Exercise: Add to function to round value of summary stat
    - include as argument to set digit rounding?
    mutate(value = round(value, 1)) %>% 
    - pipe to glue as well

## Exercise: Find and fix other issues with the data (Optional)

- filter to look into problem rows

Based on what you find with using the ... function,
TODO: Add the function name
and with using `View(mmash)`, identify other things in the dataset
that might require cleaning
- In the `data-raw/mmash.R` script Using a combination of `filter()`
and `mutate()`, tidy up the fully joined dataset (before saving with
`usethis::use_data()`), and
Rename columns to be more descriptive, remove extra columns
    - Go back and update mmash.R file, restart R, source.

## General workflow up to this point {#general-workflow}

You now have some skills and tools to allow you to reproducibly import,
process, clean, join, and eventually analyze your datasets.
For the next two exercises, you will apply these skills and tools. 
Listed below are the general workflows we've covered and that you
can use as a guideline to completing the following exercises:

- Import with the `vroom()`, `spec()`, `vroom()` workflow.
- Convert into a function with the `doc/lesson.Rmd` to `R/function.R`,
restart R, and `load_all()` workflow.
- Test that the datasets join properly while in `doc/lesson.Rmd`
then cut and paste into `data-raw/mmash.R` workflow.
- Restart R and re-create the `data/mmash.rda` dataset by
sourcing `data-raw/mmash.R` workflow.
- Restart R, load the new dataset with `load_all()`
(`Ctrl-Shift-L`), and analyze it in `doc/lesson.Rmd` workflow.
- Add any additional cleaning code to `data-raw/mmash.R` and
update the `data/mmash.rda` dataset whenever you find problems
workflow.
- Write R in code chunks in the `doc/lesson.Rmd` to further
analyze your data and check reproducibility by often knitting to
HTML workflow.
    - Part of this workflow is to also write R code to output
    in a way that looks nice in the HTML (or Word) output
    by mostly e.g. creating tables or figures of the output.

And **don't forget**, for each stage, add and commit the changes
you've made to the files into the Git history.

## Final exercise: Process and join sleep and questionnaire data

Time: 25 min

There are still a few datasets that you can join in with the current
datasets like `sleep.csv` and `questionnaire.csv`. 
Using the workflows in Section \@ref(general-workflow) as a guide,
start from the beginning and import, process, clean, make functions,
and join these two datasets in with the others so that they get 
included in the `data/mmash.rda` final dataset. Afterwards, do some
descriptive analysis using the function ...
TODO: function name?

## Exercise: Create a second dataset of only the Actigraph and RR data

Time: 25 min

The Actigraph and RR datasets contain a ton of interesting and useful
data that gets destroyed when we first summarize and then join them
with the other datasets. While we can't meaningfully join all this
data with the other datasets, we can join them on their own.

Using the workflows in Section \@ref(general-workflow) as a guide,
start from the beginning and import, process, clean, make functions,
and create a final dataset of only the `Actigraph.csv` and `RR.csv`
datasets.

- Join only these two datasets by `user_id`, `day`, and `time`.
- Name the new dataset `actigraph_rr` and save it to `data/`
by using another `usethis::use_data()` line in the `data-raw/mmash.R`
script.

Other ideas:

- Run multiple models and extract only some information?
- Run models on re-sampled sets?

## Exercise: Update the `mmash.R` script with fixes you found from EDA

## Misc

What happened? We had an error. We've encountered a problem due to
"[non-standard evaluation]" (or NSE). NSE is very commonly used in most tidyverse
packages as well as throughout base R. It's one of the first things computer 
scientists complain about when they use R, because it is such a foreign thing
in other programming languages. But NSE is what allows you to use formulas (e.g.
`y ~ x + x2` in modelling) or allows you to type out `select(Gender, BMI)`. In
other programming languages, it would be `select("Gender", "BMI")`. It gives a lot
of flexibility to use for doing data analysis, but can give some headaches when
programming in R. So instead we have to use quotes instead and use the `_at()` 
combined with `vars()` version of dplyr functions. The tidyr functions `gather`
and `spread` don't require these changes.

[non-standard evaluation]: https://adv-r.had.co.nz/Computing-on-the-language.html



`r '-->'`
