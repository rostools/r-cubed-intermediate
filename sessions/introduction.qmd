# Introduction to workshop {#sec-introduction}

```{r, include=FALSE}
# To trigger downlit usage.
library(downlit)
```

> [**Introduction slides**](/slides/introduction.html)

<div>

```{=html}
<iframe class="slide-deck" src="/slides/introduction.html"></iframe>
```

</div>

::: {.callout-note collapse="true"}
## Teacher note

The slides contain speaking notes that you can view by pressing 'S' on
the keyboard.
:::

## :book: Reading task: Our roadmap

::: {.callout-note appearance="minimal" collapse="true"}
## Teacher note

Go over the text again and use the diagrams to reinforce what our
roadmap is.
:::

**Time: \~15 minutes.**

This section provides an bigger picture view and roadmap of what we will
be doing, a bit on why we want to do it, and what it will look like in
the end. The overall practical aim or "destination" of this workshop is:

*To apply a reproducible and programmatic approach to efficiently
downloading a dataset that has multiple data files, then processing and
cleaning them all, and saving them as a single data file to use for
later analysis.*

In our case, during the workshop we want to process the DIME data so
that we have a single dataset to work with for later (hypothetical)
analyses. We have one CGM file and one sleep file for each participant,
as well as a single participant details file.

To get to a single dataset, let's work backwards:

1.  To get one final dataset, we need to join the CGM, sleep, and
    participant data together and in a way that makes sense.
2.  To join all the datasets together, they all need to be in a format
    that can be joinable. So they need to be cleaned.
3.  We need to clean the participant details data.
4.  We need to clean the CGM and sleep data.
5.  To clean the CGM data, we need to have one single CGM data frame to
    be able to clean on, but we currently have many. So we need to join
    ('bind') all the CGM data into one. This also applies to the sleep
    data.
6.  To get one CGM or sleep data frame, we need to first import it from
    each raw file.

Breaking these steps down visually, let's start with the final joining:

```{mermaid}
%%| label: "fig-roadmap-joined-data"
%%| fig-cap: "Roadmap for the workshop: Joining all the data into one."
%%| fig-alt: "A diagram representing the flow of nodes with arrows. Nodes on the left are the three data frames, with arrows into a join action node, and finally an arrow to the final data frame."
flowchart LR
  cgm[/"CGM<br>data frame"/]
  sleep[/"Sleep<br>data frame"/]
  participants[/"Participant details<br>data frame"/]
  join(Join together)
  final_data[/"One data frame<br>ready for analysis"/]

  cgm & sleep & participants --> join
  join --> final_data
```

Going backwards, to get to the single CGM data frame, we will need to
import all the files, 'bind' them together, and then clean them. The
same applies to the sleep. Visualised below for both CGM and sleep data:

```{mermaid}
%%| label: "fig-roadmap-cgm"
%%| fig-cap: "Roadmap for the workshop: Importing and cleaning all the CGM (or sleep) data files."
%%| fig-alt: "A diagram representing the flow of nodes with arrows. Nodes on the left are the individual files for CGM, that point into an import and binding action, that then move into cleaning, and finally to a single CGM data frame."
flowchart LR
  cgm_a[/"data-raw/dime/cgm/101.csv"/]
  cgm_etc[/"data-raw/dime/cgm/*.csv"/]
  cgm_z[/"data-raw/dime/cgm/127.csv"/]
  cgm[/"CGM<br>data frame"/]
  import(Import then<br>'bind' together)
  clean(Clean data)

  cgm_a & cgm_etc & cgm_z --> import
  import --> clean
  clean --> cgm
```

And for the participant details flow, it would be:

```{mermaid}
%%| label: "fig-roadmap-participant-details"
%%| fig-cap: "Roadmap for the workshop: Importing and cleaning the participant details data file."
%%| fig-alt: "A diagram representing the overall flow from start to end of the workshop, with nodes for files pointing into code and outputting a final dataframe."
flowchart TB
  participant_details[/"data-raw/dime/participant_details.csv"/]
  import(Import data)
  clean(Clean data)
  output[/"Participant details<br>data frame"/]

  participant_details --> import
  import --> clean
  clean --> output
```

We also want to make sure that whatever processing we do to the data is
reproducible, so we'll be writing the code in a way that enables and
enforces reproducibility of the code.

So how specifically will we do this? At the highest level, everything
revolves around files and folders. Below is what the project currently
looks like and what it will look like at the end of the workshop.
Notice, the only differences here are the addition of a new file in the
`data/` folder and a new HTML file in the `docs/` folder. The new file
in the `data/` folder is the final dataset we will be creating, and the
new HTML file in the `docs/` folder is the rendered Quarto document that
we will be creating.

::: {layout-ncol="2"}
### Currently looks like: {.unnumbered}

```
LearnR3
├── data/
│   └── README.md
├── data-raw/
│   ├── README.md
│   ├── dime.zip
│   ├── dime/
│   │  ├── cgm/
│   │  ├── sleep/
│   │  └── participant_details.csv
│   └── dime.R
├── docs/
│   ├── README.md
│   └── learning.qmd
├── R/
│   ├── functions.R
│   └── README.md
├── .gitignore
├── DESCRIPTION
├── LearnR3.Rproj
├── README.md
└── TODO.md
```

### End of workshop: {.unnumbered}

```
LearnR3
├── data/
│   ├── README.md
│   └── dime.csv <- Added
├── data-raw/
│   ├── README.md
│   ├── dime.zip
│   ├── dime/
│   │  ├── cgm/
│   │  ├── sleep/
│   │  └── participant_details.csv
│   └── dime.R
├── docs/
│   ├── README.md
│   ├── learning.html <- Added
│   └── learning.qmd
├── R/
│   ├── functions.R
│   └── README.md
├── .gitignore
├── DESCRIPTION
├── LearnR3.Rproj
├── README.md
└── TODO.md
```
:::

This structure, particularly the use of the `.Rproj` file and the
`DESCRIPTION` file (that we will cover in this workshop) are part of a
"project-based workflow" that is commonly used. We use this type of
workflow because we want to follow some standard conventions in R, like
having a `DESCRIPTION` metadata file, keeping raw data in the
`data-raw/` folder, and keeping (most) R scripts in the `R/`. We also
want to keep things structured to make it easier for others and
ourselves to reproduce the work.

::: callout-note
During the code-alongs, we will be working with the CGM and participant
details data. For the exercises, you will practice what you've learned
on the sleep data.
:::

{{< text_snippet sticky_up >}}

## :technologist: Exercise: What types of workflows do you use?

**Time: \~6 minutes.**

The process of learning is about taking the content you just learned and
trying to integrate it into your own context and situation, as well as
talking about it to enforce it into your brain. So:

-   Take 1 minutes to think about the workflows you use in your own
    work. Since we'll be covering different workflows in this workshop,
    we would like you to try to think of your own and how it will
    compare to the ones taught. Try to think very explicitly what you do
    and how you do it.
-   Then, with your neighbour, take 5 minutes where each of you share
    what you've thought about and discuss it. How do both of your ways
    of working compare to each other and to what was described above?

{{< text_snippet sticky_up >}}
